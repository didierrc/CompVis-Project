{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zK490Ryuy-xN"
   },
   "source": [
    "# CV Course Project: Assignment - Object Detection\n",
    "\n",
    "---\n",
    "\n",
    "**Group:**\n",
    "- Alumno 1: San Millan Rodrigues, Nadine (n.srodrigues@alumnos.upm.es)\n",
    "- Alumno 2: Sukhorukova, Anastasia (anastasia.s@alumnos.upm.es)\n",
    "- Alumno 3: Reyes Castro, Didier Yamil (didier.reyes.castro@alumnos.upm.es)\n",
    "\n",
    "**Course:** Computer Vision (CV) - 2025/26\n",
    "\n",
    "**Institution:** Polytechnic University of Madrid (UPM)\n",
    "\n",
    "**Date:** January 2026\n",
    "\n",
    "---\n",
    "## Goals\n",
    "\n",
    "The goals of the assignment are:\n",
    "\n",
    "* Put into practice acquired knowledge to detect and recognize objects of interest within a satellite image.\n",
    "\n",
    "To address this problem, you must choose one of the following options:\n",
    "*\tImplement a sliding window strategy to process the whole image, and then train a classifier that determines whether each window includes or not an object of interest. In this way, you can use previous image classification model to infer the object category.\n",
    "*\tBuild a single-stage object detection model (e.g., YOLO, SSD, RetinaNet, etc.).\n",
    "*\tBuild a two-stage object detection model (e.g., Faster R-CNN, R-FCN, etc.).\n",
    "\n",
    "Follow the link below to download the detection data set “xview_detection”: [https://drive.upm.es/s/P7nEf3Bygns7tbM](https://drive.upm.es/s/P7nEf3Bygns7tbM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Setup and Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Install and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow[and-cuda] numpy rasterio keras-cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the necessary libraries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid, warnings, json\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import keras_cv\n",
    "from keras_cv import bounding_box\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import TerminateOnNaN, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as col\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if GPU is available for training the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T07:52:48.484923Z",
     "iopub.status.busy": "2025-09-22T07:52:48.484536Z",
     "iopub.status.idle": "2025-09-22T07:53:01.287517Z",
     "shell.execute_reply": "2025-09-22T07:53:01.286438Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-22 07:52:50.248064: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-22 07:52:50.701721: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-22 07:52:50.701808: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-22 07:52:50.801276: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random seed setting function for reproducibility..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "def set_seed(seed_value):\n",
    "    np.random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Load the Dataset & Image Loader\n",
    "\n",
    "Before loading the dataset, set the path to the folder containing the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T15:41:41.841195340Z",
     "start_time": "2023-11-21T15:41:41.832078114Z"
    },
    "execution": {
     "iopub.execute_input": "2025-09-22T07:53:01.293694Z",
     "iopub.status.busy": "2025-09-22T07:53:01.292546Z",
     "iopub.status.idle": "2025-09-22T07:53:01.300703Z",
     "shell.execute_reply": "2025-09-22T07:53:01.299609Z"
    },
    "id": "TGvvuEREy-xT"
   },
   "outputs": [],
   "source": [
    "class GenericObject:\n",
    "    \"\"\"\n",
    "    Generic object data.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.id = uuid.uuid4()\n",
    "        self.bb = (-1, -1, -1, -1)\n",
    "        self.category= -1\n",
    "        self.score = -1\n",
    "\n",
    "class GenericImage:\n",
    "    \"\"\"\n",
    "    Generic image data.\n",
    "    \"\"\"\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.tile = np.array([-1, -1, -1, -1])  # (pt_x, pt_y, pt_x+width, pt_y+height)\n",
    "        self.objects = list([])\n",
    "\n",
    "    def add_object(self, obj: GenericObject):\n",
    "        self.objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T07:53:01.303083Z",
     "iopub.status.busy": "2025-09-22T07:53:01.302909Z",
     "iopub.status.idle": "2025-09-22T07:53:01.306541Z",
     "shell.execute_reply": "2025-09-22T07:53:01.305922Z"
    }
   },
   "outputs": [],
   "source": [
    "categories = {0: 'Small car', 1: 'Bus', 2: 'Truck', 3: 'Building'}\n",
    "DETECTION_IMAGES_PATH = '/kaggle/input/xview-dataset/xview_detection/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T07:53:01.308657Z",
     "iopub.status.busy": "2025-09-22T07:53:01.308494Z",
     "iopub.status.idle": "2025-09-22T07:53:02.075486Z",
     "shell.execute_reply": "2025-09-22T07:53:02.074630Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_geoimage(filename):\n",
    "    warnings.filterwarnings('ignore', category=rasterio.errors.NotGeoreferencedWarning)\n",
    "    src_raster = rasterio.open(DETECTION_IMAGES_PATH + filename, 'r')\n",
    "    # RasterIO to OpenCV (see inconsistencies between libjpeg and libjpeg-turbo)\n",
    "    input_type = src_raster.profile['dtype']\n",
    "    input_channels = src_raster.count\n",
    "    img = np.zeros((src_raster.height, src_raster.width, src_raster.count), dtype=input_type)\n",
    "    for band in range(input_channels):\n",
    "        img[:, :, band] = src_raster.read(band+1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T15:48:22.102317718Z",
     "start_time": "2023-11-21T15:48:20.911767630Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-22T07:53:02.080700Z",
     "iopub.status.busy": "2025-09-22T07:53:02.080332Z",
     "iopub.status.idle": "2025-09-22T07:53:03.862197Z",
     "shell.execute_reply": "2025-09-22T07:53:03.861781Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load database\n",
    "json_file = DETECTION_IMAGES_PATH + 'xview_det_train.json'\n",
    "with open(json_file) as ifs:\n",
    "    json_data = json.load(ifs)\n",
    "ifs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T07:53:03.864695Z",
     "iopub.status.busy": "2025-09-22T07:53:03.864520Z",
     "iopub.status.idle": "2025-09-22T07:58:06.963113Z",
     "shell.execute_reply": "2025-09-22T07:58:06.962621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Small car': 188300, 'Bus': 6269, 'Truck': 10600, 'Building': 275943}\n"
     ]
    }
   ],
   "source": [
    "counts = dict.fromkeys(categories.values(), 0)\n",
    "anns = []\n",
    "for json_img in json_data['images'].values():\n",
    "    image = GenericImage(json_img['filename'])\n",
    "    image.tile = np.array([0, 0, json_img['width'], json_img['height']])\n",
    "    for json_ann in [elem for elem in json_data['annotations'].values() if elem['image_id'] == json_img['image_id']]:\n",
    "        obj = GenericObject()\n",
    "        obj.id = json_ann['image_id']\n",
    "        obj.bb = (int(json_ann['bbox'][0]), int(json_ann['bbox'][1]), int(json_ann['bbox'][2]), int(json_ann['bbox'][3]))\n",
    "        obj.category = json_ann['category_id']\n",
    "        counts[obj.category] += 1\n",
    "        image.add_object(obj)\n",
    "    anns.append(image)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T07:58:15.526651Z",
     "iopub.status.busy": "2025-09-22T07:58:15.526522Z",
     "iopub.status.idle": "2025-09-22T07:58:15.531805Z",
     "shell.execute_reply": "2025-09-22T07:58:15.530702Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_generator(filename, tile, bboxes, categories):\n",
    "    def load_sample(filepath):\n",
    "        image = load_geoimage(filepath.numpy().decode('utf-8'))\n",
    "        return tf.cast(image, tf.uint8)\n",
    "    # Load image\n",
    "    img = tf.squeeze(tf.py_function(func=load_sample, inp=[filename], Tout=[tf.uint8]), axis=0)  # tf.print(tf.shape(img)) -> [H, W, 3]\n",
    "    img_roi = tf.image.pad_to_bounding_box(img, 0, 0, 640, 640)\n",
    "    return {'images': tf.cast(img_roi, tf.float32), 'bounding_boxes': {'boxes': bboxes, 'classes': categories}}\n",
    "\n",
    "def ragged_to_dense(inputs):\n",
    "    return {'images': inputs['images'].to_tensor(), 'bounding_boxes': bounding_box.to_dense(inputs['bounding_boxes'], max_boxes=2000)}\n",
    "\n",
    "def dict_to_tuple(inputs):\n",
    "    return inputs['images'], inputs['bounding_boxes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1 Training\n",
    "\n",
    "Designing and training a detector to deal with the “xview_detection” perception task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Setup\n",
    "\n",
    "First, split the dataset into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T07:58:06.965394Z",
     "iopub.status.busy": "2025-09-22T07:58:06.965234Z",
     "iopub.status.idle": "2025-09-22T07:58:08.579750Z",
     "shell.execute_reply": "2025-09-22T07:58:08.579024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 6845\n",
      "Number of validation images: 761\n"
     ]
    }
   ],
   "source": [
    "anns_train, anns_valid = train_test_split(anns, test_size=0.1, \n",
    "                                          random_state=RANDOM_SEED, \n",
    "                                          shuffle=True)\n",
    "print('Number of training images: ' + str(len(anns_train)))\n",
    "print('Number of validation images: ' + str(len(anns_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the **NMS technique to filter overlapping bounding boxes** and using the pre-defined **YOLOv8** model from KerasCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T07:58:08.582274Z",
     "iopub.status.busy": "2025-09-22T07:58:08.581835Z",
     "iopub.status.idle": "2025-09-22T07:58:15.386279Z",
     "shell.execute_reply": "2025-09-22T07:58:15.385884Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Loading the model...')\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.2\n",
    "IOU_THRESHOLD = 0.7\n",
    "\n",
    "prediction_decoder = keras_cv.layers.NonMaxSuppression(bounding_box_format='xyxy', \n",
    "                                                       from_logits=False, \n",
    "                                                       confidence_threshold=CONFIDENCE_THRESHOLD, \n",
    "                                                       iou_threshold=IOU_THRESHOLD)\n",
    "\n",
    "model = keras_cv.models.YOLOV8Detector.from_preset(preset='yolo_v8_xs_backbone_coco', \n",
    "                                                   num_classes=len(categories), \n",
    "                                                   load_weights=True, \n",
    "                                                   bounding_box_format='xyxy', \n",
    "                                                   prediction_decoder=prediction_decoder)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the **SGD optimizer** and **Binary Crossentropy** loss for classification and **CIOU loss for bounding box regression**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T07:58:15.500766Z",
     "iopub.status.busy": "2025-09-22T07:58:15.500616Z",
     "iopub.status.idle": "2025-09-22T07:58:15.519599Z",
     "shell.execute_reply": "2025-09-22T07:58:15.519005Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = SGD(learning_rate=1e-3, \n",
    "          momentum=0.9, \n",
    "          global_clipnorm=10.0)\n",
    "\n",
    "model.compile(optimizer=opt, \n",
    "              classification_loss='binary_crossentropy', \n",
    "              box_loss='ciou', \n",
    "              jit_compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks for training the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T07:58:15.521333Z",
     "iopub.status.busy": "2025-09-22T07:58:15.521197Z",
     "iopub.status.idle": "2025-09-22T07:58:15.525012Z",
     "shell.execute_reply": "2025-09-22T07:58:15.524416Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'model.keras'\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(MODEL_NAME, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=10, verbose=1)\n",
    "early_stop = EarlyStopping('val_loss', patience=40, verbose=1)\n",
    "terminate = TerminateOnNaN()\n",
    "callbacks = [model_checkpoint, reduce_lr, early_stop, terminate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T07:58:15.533490Z",
     "iopub.status.busy": "2025-09-22T07:58:15.533354Z",
     "iopub.status.idle": "2025-09-22T07:58:24.607344Z",
     "shell.execute_reply": "2025-09-22T07:58:24.606326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate the list of objects from annotations\n",
    "filenames_train, tiles_train, bboxes_train, categories_train = zip(*list(map(lambda img_ann: (img_ann.filename, list(img_ann.tile), list([list(obj_ann.bb) for obj_ann in img_ann.objects]), list([list(categories.keys())[list(categories.values()).index(obj_ann.category)] for obj_ann in img_ann.objects])), anns_train)))\n",
    "filenames_valid, tiles_valid, bboxes_valid, categories_valid = zip(*list(map(lambda img_ann: (img_ann.filename, list(img_ann.tile), list([list(obj_ann.bb) for obj_ann in img_ann.objects]), list([list(categories.keys())[list(categories.values()).index(obj_ann.category)] for obj_ann in img_ann.objects])), anns_valid)))\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((tf.cast(filenames_train, tf.string), tf.cast(tiles_train, tf.int32), tf.cast(tf.ragged.constant(bboxes_train), tf.float32).to_tensor(), tf.cast(tf.ragged.constant(categories_train), tf.float32).to_tensor()))\n",
    "ds_valid = tf.data.Dataset.from_tensor_slices((tf.cast(filenames_valid, tf.string), tf.cast(tiles_valid, tf.int32), tf.cast(tf.ragged.constant(bboxes_valid), tf.float32).to_tensor(), tf.cast(tf.ragged.constant(categories_valid), tf.float32).to_tensor()))\n",
    "ds_train = ds_train.map(image_generator, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_valid = ds_valid.map(image_generator, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# Generators\n",
    "batch_size = 4\n",
    "ds_train = ds_train.shuffle(batch_size*5)\n",
    "ds_train = ds_train.ragged_batch(batch_size=batch_size, drop_remainder=True)\n",
    "ds_valid = ds_valid.ragged_batch(batch_size=batch_size, drop_remainder=True)\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "    layers=[keras_cv.layers.RandomFlip(mode='horizontal_and_vertical', bounding_box_format='xyxy'),\n",
    "            keras_cv.layers.RandomShear(x_factor=0.2, y_factor=0.2, bounding_box_format='xyxy'),\n",
    "            keras_cv.layers.RandomColorDegeneration(factor=0.5)])\n",
    "ds_train = ds_train.map(data_augmentation, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# Bounding box tensors need to be Dense instead of Ragged\n",
    "ds_train = ds_train.map(ragged_to_dense, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_valid = ds_valid.map(ragged_to_dense, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "ds_valid = ds_valid.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T07:58:24.609634Z",
     "iopub.status.busy": "2025-09-22T07:58:24.609484Z",
     "iopub.status.idle": "2025-09-23T04:08:14.295657Z",
     "shell.execute_reply": "2025-09-23T04:08:14.295107Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Training model...')\n",
    "EPOCHS = 40\n",
    "\n",
    "train_steps, valid_steps = len(ds_train), len(ds_valid)\n",
    "h = model.fit(ds_train, \n",
    "              steps_per_epoch=train_steps, \n",
    "              validation_data=ds_valid, \n",
    "              validation_steps=valid_steps, \n",
    "              epochs=EPOCHS, \n",
    "              callbacks=callbacks, verbose=1)\n",
    "\n",
    "# Best validation model\n",
    "best_idx = int(np.argmin(h.history['val_loss']))\n",
    "best_value = np.min(h.history['val_loss'])\n",
    "print('Best validation model: epoch ' + str(best_idx+1), ' - val_loss ' + str(best_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "pyX0YILvy-xa",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 2 Evaluation\n",
    "\n",
    "Compute validation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T04:08:14.298013Z",
     "iopub.status.busy": "2025-09-23T04:08:14.297846Z",
     "iopub.status.idle": "2025-09-23T04:08:14.371100Z",
     "shell.execute_reply": "2025-09-23T04:08:14.370016Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def area_intersection(boxes, box):\n",
    "    xmin = np.maximum(np.min(boxes[:, 0::2], axis=1), np.min(box[0::2]))\n",
    "    ymin = np.maximum(np.min(boxes[:, 1::2], axis=1), np.min(box[1::2]))\n",
    "    xmax = np.minimum(np.max(boxes[:, 0::2], axis=1), np.max(box[0::2]))\n",
    "    ymax = np.minimum(np.max(boxes[:, 1::2], axis=1), np.max(box[1::2]))\n",
    "    w = np.maximum(xmax - xmin + 1.0, 0.0)\n",
    "    h = np.maximum(ymax - ymin + 1.0, 0.0)\n",
    "    return w * h\n",
    "\n",
    "def area_union(boxes, box):\n",
    "    area_anns = (np.max(box[0::2])-np.min(box[0::2])+1.0) * (np.max(box[1::2])-np.min(box[1::2])+1.0)\n",
    "    area_pred = (np.max(boxes[:, 0::2], axis=1)-np.min(boxes[:, 0::2], axis=1)+1.0) * (np.max(boxes[:, 1::2], axis=1)-np.min(boxes[:, 1::2], axis=1)+1.0)\n",
    "    return area_anns + area_pred - area_intersection(boxes, box)\n",
    "\n",
    "def calc_iou(boxes, box):\n",
    "    iou = area_intersection(boxes, box) / area_union(boxes, box)\n",
    "    max_value = np.max(iou)\n",
    "    max_index = np.argmax(iou)\n",
    "    return max_value, max_index\n",
    "\n",
    "def calc_ap(rec, prec):\n",
    "    # First append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.0], rec, [1.0]))\n",
    "    mpre = np.concatenate(([0.0], prec, [0.0]))\n",
    "    # Compute the precision envelope\n",
    "    for i in range(mpre.size-1, 0, -1):\n",
    "        mpre[i-1] = np.maximum(mpre[i-1], mpre[i])\n",
    "    # To calculate area under PR curve, look for points where X axis (recall) changes value\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((mrec[i+1] - mrec[i]) * mpre[i+1])\n",
    "    return ap\n",
    "\n",
    "def draw_confusion_matrix(cm, categories):\n",
    "    # Draw confusion matrix\n",
    "    fig = plt.figure(figsize=[6.4*pow(len(categories), 0.5), 4.8*pow(len(categories), 0.5)])\n",
    "    ax = fig.add_subplot(111)\n",
    "    cm = cm.astype('float') / np.maximum(cm.sum(axis=1)[:, np.newaxis], np.finfo(np.float64).eps)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.get_cmap('Blues'))\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), xticklabels=categories, yticklabels=categories, ylabel='Annotation', xlabel='Prediction')\n",
    "    # Rotate the tick labels and set their alignment\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    # Loop over data dimensions and create text annotations\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], '.2f'), ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=int(20-pow(len(categories), 0.5)))\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def draw_precision_recall(precisions, recalls, categories):\n",
    "    # Draw precision-recall curves for each category\n",
    "    fig = plt.figure(figsize=[6.4*pow(len(categories), 0.5), 4.8*pow(len(categories), 0.5)])\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    c_dark = list(filter(lambda x: x.startswith('dark'), col.cnames.keys()))\n",
    "    aps = []\n",
    "    # Compare categories for a specific algorithm\n",
    "    for idx in range(len(categories)):\n",
    "        plt.plot(recalls[idx], precisions[idx], color=c_dark[idx], label=categories[idx], linewidth=4.0)\n",
    "        aps.append(calc_ap(recalls[idx], precisions[idx]))\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    labels = [str(val + ' [' + \"{:.3f}\".format(aps[idx]) + ']') for idx, val in enumerate(labels)]\n",
    "    handles = [h for (ap, h) in sorted(zip(aps, handles), key=lambda x: x[0], reverse=True)]\n",
    "    labels = [l for (ap, l) in sorted(zip(aps, labels), key=lambda x: x[0], reverse=True)]\n",
    "    leg = plt.legend(handles, labels, loc='upper right')\n",
    "    leg.set_zorder(100)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.grid(\"on\", linestyle=\"--\", linewidth=2.0)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-23T04:08:14.373872Z",
     "iopub.status.busy": "2025-09-23T04:08:14.373705Z",
     "iopub.status.idle": "2025-09-23T04:10:49.229845Z",
     "shell.execute_reply": "2025-09-23T04:10:49.228874Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x467/x467548/.local/lib/python3.11/site-packages/keras_cv/src/models/task.py:43: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n",
      "/home/x467/x467548/.local/lib/python3.11/site-packages/keras_cv/src/models/task.py:43: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n",
      "100%|██████████| 761/761 [02:23<00:00,  5.29it/s]\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(MODEL_NAME)\n",
    "# Generate the list of objects from annotations\n",
    "ds_valid = tf.data.Dataset.from_tensor_slices((tf.cast(filenames_valid, tf.string), tf.cast(tiles_valid, tf.int32), tf.cast(tf.ragged.constant(bboxes_valid), tf.float32).to_tensor(), tf.cast(tf.ragged.constant(categories_valid), tf.float32).to_tensor()))\n",
    "ds_valid = ds_valid.map(image_generator, num_parallel_calls=tf.data.AUTOTUNE).cache()\n",
    "ds_valid = ds_valid.batch(batch_size=1)\n",
    "ds_valid = ds_valid.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "# Process each tile sequentially\n",
    "iterator = iter(ds_valid)\n",
    "annotations, predictions = {}, {}\n",
    "for ann in tqdm(anns_valid):\n",
    "    # Save annotations\n",
    "    annotations.setdefault(ann.filename, {})\n",
    "    predictions.setdefault(ann.filename, {})\n",
    "    for obj in ann.objects:\n",
    "        annotations[ann.filename].setdefault(obj.category, {'bbox': []})\n",
    "        annotations[ann.filename][obj.category]['bbox'].append(obj.bb)\n",
    "    # Save prediction\n",
    "    image, _ = next(iterator)\n",
    "    y_pred = model.predict(image, verbose=0)\n",
    "    for i in range(np.squeeze(y_pred['num_detections'])):\n",
    "        obj = GenericObject()\n",
    "        bbox = np.squeeze(y_pred['boxes'])[i]\n",
    "        obj.bb = (bbox[0], bbox[1], bbox[2], bbox[3])\n",
    "        obj.category = categories[np.squeeze(y_pred['classes'])[i]]\n",
    "        obj.score = np.squeeze(y_pred['confidence'])[i]\n",
    "        predictions[ann.filename].setdefault(obj.category, {'bbox': [], 'confidence': []})\n",
    "        predictions[ann.filename][obj.category]['bbox'].append(obj.bb)\n",
    "        predictions[ann.filename][obj.category]['confidence'].append(obj.score)  # sort detections by confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T04:10:49.232029Z",
     "iopub.status.busy": "2025-09-23T04:10:49.231877Z",
     "iopub.status.idle": "2025-09-23T04:10:54.674720Z",
     "shell.execute_reply": "2025-09-23T04:10:54.673770Z"
    },
    "id": "QsA9Dx57y-xf"
   },
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "default_cls = 'BACKGROUND'\n",
    "y_true, y_pred = [], []  # confusion matrix\n",
    "tps, confidences = dict(), dict()  # draw precision-recall curves for each category\n",
    "for cls in categories.values():\n",
    "    # Compute TP, FP and FN for each image\n",
    "    tps[cls], confidences[cls] = [], []\n",
    "    for f in predictions:\n",
    "        # Sort 'cls' predictions by confidence for each file\n",
    "        pred_boxes, pred_confidences = [], []\n",
    "        if cls in predictions[f].keys():\n",
    "            for idx in range(len(predictions[f][cls]['bbox'])):\n",
    "                pred_boxes.append(predictions[f][cls]['bbox'][idx])\n",
    "                pred_confidences.append(predictions[f][cls]['confidence'][idx])\n",
    "            sorted_ind = np.argsort(-np.array(pred_confidences))\n",
    "            pred_boxes = np.array(pred_boxes)[sorted_ind, :]\n",
    "        pred_boxes = np.array(pred_boxes).astype(float)\n",
    "        # Define 'cls' annotations for each file\n",
    "        anno_boxes = []\n",
    "        if cls in annotations[f].keys():\n",
    "            anno_boxes = annotations[f][cls]['bbox']\n",
    "        anno_boxes = np.array(anno_boxes).astype(float)\n",
    "        # Define horizontal or oriented bounding boxes\n",
    "        anno_indices = list(range(len(anno_boxes)))\n",
    "        # Compare a single prediction 'pred_box' with all annotations 'anno_boxes'\n",
    "        for pred_idx, pred_box in enumerate(pred_boxes):\n",
    "            # A prediction is correct if its IoU with the ground truth is above the threshold\n",
    "            iou_value, ann_index = calc_iou(anno_boxes, pred_box) if len(anno_boxes) > 0 else (-1, -1)\n",
    "            if iou_value > threshold and ann_index in anno_indices:\n",
    "                # TP\n",
    "                anno_indices.remove(int(ann_index))\n",
    "                tps[cls] += [1.0]\n",
    "                y_true += [cls]\n",
    "            else:\n",
    "                # FP\n",
    "                tps[cls] += [0.0]\n",
    "                y_true += [default_cls]\n",
    "            y_pred += [cls]\n",
    "            confidences[cls] += [pred_confidences[pred_idx]]\n",
    "        # FN\n",
    "        y_true += [cls] * len(anno_indices)\n",
    "        y_pred += [default_cls] * len(anno_indices)\n",
    "y_true, y_pred = np.array(y_true), np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T04:10:54.676744Z",
     "iopub.status.busy": "2025-09-23T04:10:54.676597Z",
     "iopub.status.idle": "2025-09-23T04:10:55.027697Z",
     "shell.execute_reply": "2025-09-23T04:10:55.027315Z"
    },
    "id": "6vXYDcQ0y-xh",
    "outputId": "2b814533-4932-435c-c595-2d03ff96af52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Small car: Recall: 43.535% Precision: 57.917% AP: 32.940%\n",
      "> Bus: Recall: 10.469% Precision: 32.683% AP: 4.655%\n",
      "> Truck: Recall: 0.479% Precision: 41.667% AP: 0.363%\n",
      "> Building: Recall: 50.851% Precision: 54.603% AP: 40.963%\n",
      "mAccuracy: 33.921%\n",
      "mRecall: 21.067%\n",
      "mPrecision: 37.374%\n",
      "mAP: 19.730%\n"
     ]
    }
   ],
   "source": [
    "# Compute AP metric\n",
    "precision_list, recall_list, ap_list = [], [], []\n",
    "for cls in categories.values():\n",
    "    sorted_ind = np.argsort(-np.array(confidences[cls]))\n",
    "    tp = np.cumsum(np.array(tps[cls])[sorted_ind], dtype=float)\n",
    "    recall = np.array([0.0]) if len(tp) == 0 else tp / np.maximum(np.sum(y_true == cls), np.finfo(np.float64).eps)\n",
    "    precision = np.array([0.0]) if len(tp) == 0 else tp / np.maximum(list(range(1, np.sum(y_pred == cls)+1)), np.finfo(np.float64).eps)\n",
    "    ap = calc_ap(recall, precision)\n",
    "    print('> %s: Recall: %.3f%% Precision: %.3f%% AP: %.3f%%' % (cls, recall[-1]*100, precision[-1]*100, ap*100))\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    ap_list.append(ap)\n",
    "mean_ap = np.mean(ap_list)\n",
    "print('mAccuracy: %.3f%%' % (accuracy_score(y_true, y_pred)*100))\n",
    "print('mRecall: %.3f%%' % (recall_score(y_true, y_pred, average='macro', zero_division=1)*100))\n",
    "print('mPrecision: %.3f%%' % (precision_score(y_true, y_pred, average='macro', zero_division=1)*100))\n",
    "print('mAP: %.3f%%' % (mean_ap*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T04:10:55.029560Z",
     "iopub.status.busy": "2025-09-23T04:10:55.029426Z",
     "iopub.status.idle": "2025-09-23T04:10:55.640774Z",
     "shell.execute_reply": "2025-09-23T04:10:55.639708Z"
    },
    "id": "P30Z5qLGy-xi",
    "outputId": "62bf9fc1-bdfe-48a8-8060-d52fe3a81dab"
   },
   "outputs": [],
   "source": [
    "names = list(categories.values()).copy()\n",
    "names.insert(0, default_cls)\n",
    "cm = confusion_matrix(y_true, y_pred, labels=names)\n",
    "print('Confusion matrix:')\n",
    "print(cm)\n",
    "draw_confusion_matrix(cm, names)\n",
    "draw_precision_recall(precision_list, recall_list, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "pyX0YILvy-xa",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3 Testing\n",
    "Try to improve the results provided in the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T04:10:55.642839Z",
     "iopub.status.busy": "2025-09-23T04:10:55.642687Z",
     "iopub.status.idle": "2025-09-23T04:10:55.676514Z",
     "shell.execute_reply": "2025-09-23T04:10:55.675483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing images: 852\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "anns = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(DETECTION_IMAGES_PATH + 'xview_test'):\n",
    "    for filename in filenames:\n",
    "        image = GenericImage(dirpath[27:] + '/' + filename)\n",
    "        image.tile = np.array([0, 0, 640, 640])\n",
    "        anns.append(image)\n",
    "print('Number of testing images: ' + str(len(anns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T04:10:55.679119Z",
     "iopub.status.busy": "2025-09-23T04:10:55.678951Z",
     "iopub.status.idle": "2025-09-23T04:12:33.919517Z",
     "shell.execute_reply": "2025-09-23T04:12:33.918582Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x467/x467548/.local/lib/python3.11/site-packages/keras_cv/src/models/task.py:43: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n",
      "/home/x467/x467548/.local/lib/python3.11/site-packages/keras_cv/src/models/task.py:43: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return id(getattr(self, attr)) not in self._functional_layer_ids\n",
      "100%|██████████| 852/852 [01:27<00:00,  9.72it/s]\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(MODEL_NAME)\n",
    "# Generate the list of objects from annotations\n",
    "filenames_test, tiles_test, bboxes_test, categories_test = zip(*list(map(lambda img_ann: (img_ann.filename, list(img_ann.tile), list([list(obj_ann.bb) for obj_ann in img_ann.objects]), list([list(categories.keys())[list(categories.values()).index(obj_ann.category)] for obj_ann in img_ann.objects])), anns)))\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((tf.cast(filenames_test, tf.string), tf.cast(tiles_test, tf.int32), tf.cast(tf.ragged.constant(bboxes_test), tf.float32).to_tensor(), tf.cast(tf.ragged.constant(categories_test), tf.float32).to_tensor()))\n",
    "ds_test = ds_test.map(image_generator, num_parallel_calls=tf.data.AUTOTUNE).cache()\n",
    "ds_test = ds_test.batch(batch_size=1)\n",
    "ds_test = ds_test.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "# Process each tile sequentially\n",
    "iterator = iter(ds_test)\n",
    "predictions = {}\n",
    "for ann in tqdm(anns):\n",
    "    # Generate prediction\n",
    "    image, _ = next(iterator)\n",
    "    y_pred = model.predict(image, verbose=0)\n",
    "    predictions.setdefault(ann.filename, {})\n",
    "    for i in range(np.squeeze(y_pred['num_detections'])):\n",
    "        obj = GenericObject()\n",
    "        bbox = np.squeeze(y_pred['boxes'])[i]\n",
    "        obj.bb = (bbox[0], bbox[1], bbox[2], bbox[3])\n",
    "        obj.category = categories[np.squeeze(y_pred['classes'])[i]]\n",
    "        obj.score = np.squeeze(y_pred['confidence'])[i]\n",
    "        predictions[ann.filename].setdefault(obj.category, {'bbox': [], 'confidence': []})\n",
    "        predictions[ann.filename][obj.category]['bbox'].append(obj.bb)\n",
    "        predictions[ann.filename][obj.category]['confidence'].append(obj.score)  # sort detections by confidence\n",
    "# Save prediction\n",
    "predictions_data = {\"images\": {}, \"annotations\": {}, \"categories\": {}}\n",
    "predictions_data[\"categories\"] = categories\n",
    "imgs_idx, annos_idx = 0, 0\n",
    "for pred in predictions:\n",
    "    num_objects = 0\n",
    "    for cat in predictions[pred]:\n",
    "        for bb in predictions[pred][cat]['bbox']:\n",
    "            num_objects += len(predictions[pred][cat]['bbox'])\n",
    "    image_data = {\"image_id\": pred.split('/')[-1], \"filename\": pred, \"num_objects\": num_objects, \"width\": 640, \"height\": 640}\n",
    "    predictions_data[\"images\"][imgs_idx] = image_data\n",
    "    imgs_idx += 1\n",
    "    bboxes, confs = [], []\n",
    "    for cat in predictions[pred]:\n",
    "        for i in range(len(predictions[pred][cat]['bbox'])):  \n",
    "            bbox = predictions[pred][cat]['bbox'][i]\n",
    "            conf = predictions[pred][cat]['confidence'][i]\n",
    "            annotation_data = {\"image_id\": pred.split('/')[-1], \"category_id\": cat, \"bbox\": (int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])), \"confidence\": str(conf)}\n",
    "            predictions_data[\"annotations\"][annos_idx] = annotation_data\n",
    "            annos_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T04:12:33.921890Z",
     "iopub.status.busy": "2025-09-23T04:12:33.921720Z",
     "iopub.status.idle": "2025-09-23T04:12:34.258451Z",
     "shell.execute_reply": "2025-09-23T04:12:34.257412Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"prediction.json\", \"w\") as outfile:\n",
    "    json.dump(predictions_data, outfile)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "resnet15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
